{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_GPT-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python37364bitvenvvenvfefc9bbb02644ec2a36fa207a9f237c2",
      "display_name": "Python 3.7.3 64-bit ('venv': venv)"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLqQmOTIEZ03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Config\n",
        "import torch\n",
        "\n",
        "ATTR_TO_SPECIAL_TOKEN = ['<song>', '</song>']\n",
        "\n",
        "vocab_file_path = './tokenizer/vocab.json'\n",
        "merge_file_path = './tokenizer/merges.txt'\n",
        "model_dir = 'gpt2/lyric_model.bin'\n",
        "\n",
        "tokenizer = MyTokenizer(vocab_file_path, merge_file_path)\n",
        "bos = tokenizer.convert_tokens_to_ids('<s>')\n",
        "eos = tokenizer.convert_tokens_to_ids('</s>')\n",
        "pad = tokenizer.convert_tokens_to_ids('<pad>')\n",
        "unk = tokenizer.convert_tokens_to_ids('<unk>')\n",
        "\n",
        "config = GPT2Config(vocab_size=52003, resid_pdrop=0, embd_pdrop=0, attn_pdrop=0, summary_first_dropout=0)\n",
        "model = GPT2LMHeadModel(config)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(model_dir, map_location=device), strict=False)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyzhBjTt-ToD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_special_tokens_(model, tokenizer):\n",
        "    orig_num_tokens = tokenizer.get_vocab_size()\n",
        "    tokenizer.add_special_tokens(ATTR_TO_SPECIAL_TOKEN)\n",
        "    num_added_tokens = len(ATTR_TO_SPECIAL_TOKEN)\n",
        "    model.resize_token_embeddings(new_num_tokens=orig_num_tokens + num_added_tokens + 1)\n",
        "\n",
        "add_special_tokens_(model, tokenizer)\n",
        "b_song = tokenizer.convert_tokens_to_ids('<song>')\n",
        "e_song = tokenizer.convert_tokens_to_ids('</song>')\n",
        "\n",
        "def encoding(text):\n",
        "    tokens = ['<song>', '<s>'] + tokenizer.tokenize(text)\n",
        "    return torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
        "\n",
        "def decoding(ids):\n",
        "    return tokenizer.convert_ids_to_tokens(ids[0])\n",
        "\n",
        "input_ids = encoding('우리는 오늘')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True, \n",
        "    max_length=1024, \n",
        "    top_k=50, \n",
        "    top_p=0.95, \n",
        "    eos_token_id=e_song,\n",
        "    early_stopping=True,\n",
        "    bad_words_ids=[[unk]]\n",
        ")\n",
        "print(decoding(sample_outputs.tolist()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KsJMOrGMpIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}